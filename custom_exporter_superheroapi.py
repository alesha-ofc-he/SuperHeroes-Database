#!/usr/bin/env python3
"""
Custom Exporter –¥–ª—è Assignment #4 - Wikipedia API (FIXED)
–ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—É–ø–µ—Ä–≥–µ—Ä–æ—è—Ö –∏–∑ Wikipedia
–ü—É–±–ª–∏–∫—É–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –≤ Prometheus —Ñ–æ—Ä–º–∞—Ç–µ
–û–±–Ω–æ–≤–ª—è–µ—Ç –∫–∞–∂–¥—ã–µ 20 —Å–µ–∫—É–Ω–¥

100% –†–ê–ë–û–¢–ê–ï–¢ - –ë–ï–ó –†–ï–ì–ò–°–¢–†–ê–¶–ò–ò! (–ø—É–±–ª–∏—á–Ω—ã–π API)
–§–ò–ö–°–ò–†–û–í–ê–ù: –î–æ–±–∞–≤–ª–µ–Ω User-Agent header
"""

import os
import time
import logging
import requests
from http.server import HTTPServer, BaseHTTPRequestHandler
from threading import Thread
from prometheus_client import CollectorRegistry, Gauge, Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST

# ============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# ============================================================================
EXPORTER_PORT = int(os.getenv("EXPORTER_PORT", "8000"))
SCRAPE_INTERVAL = int(os.getenv("SCRAPE_INTERVAL", "20"))

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

API_BASE = "https://en.wikipedia.org/w/api.php"

# User-Agent –¥–ª—è Wikipedia API (–û–ë–Ø–ó–ê–¢–ï–õ–ï–ù!)
HEADERS = {
    'User-Agent': 'SuperheroExporter/1.0 (Custom Prometheus Exporter; +https://github.com/)'
}

# –°—É–ø–µ—Ä–≥–µ—Ä–æ–∏ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ (–∏–∑ Wikipedia)
HEROES = [
    "Superman",
    "Batman",
    "Spider-Man",
    "Wonder Woman",
    "Iron Man",
    "Captain America",
    "Thor",
    "Black Widow",
    "Hawkeye",
    "Black Panther"
]

# ============================================================================
# –ú–ï–¢–†–ò–ö–ò PROMETHEUS - 30+ –º–µ—Ç—Ä–∏–∫
# ============================================================================
registry = CollectorRegistry()

# –ì–†–£–ü–ü–ê 1: –°–¢–ê–¢–¨–ò –ò –°–¢–†–ê–ù–ò–¶–´ (5 –º–µ—Ç—Ä–∏–∫)
total_heroes_monitored = Gauge('wikipedia_heroes_monitored', 'Total heroes monitored', registry=registry)
total_hero_pages = Gauge('wikipedia_hero_pages_total', 'Total hero Wikipedia pages found', registry=registry)
pages_with_images = Gauge('wikipedia_pages_with_images', 'Pages with images', registry=registry)
pages_with_categories = Gauge('wikipedia_pages_with_categories', 'Pages with categories', registry=registry)
pages_in_mainspace = Gauge('wikipedia_pages_mainspace', 'Pages in main namespace', registry=registry)

# –ì–†–£–ü–ü–ê 2: –°–û–î–ï–†–ñ–ê–ù–ò–ï –°–¢–†–ê–ù–ò–¶ (5 –º–µ—Ç—Ä–∏–∫)
avg_page_length = Gauge('wikipedia_avg_page_length_chars', 'Average page length in characters', registry=registry)
avg_sections = Gauge('wikipedia_avg_sections_per_page', 'Average sections per page', registry=registry)
avg_references = Gauge('wikipedia_avg_references_per_page', 'Average references per page', registry=registry)
avg_links = Gauge('wikipedia_avg_links_per_page', 'Average links per page', registry=registry)
max_page_length = Gauge('wikipedia_max_page_length_chars', 'Longest page length', registry=registry)

# –ì–†–£–ü–ü–ê 3: –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ì–ï–†–û–Ø–• (6 –º–µ—Ç—Ä–∏–∫)
hero_page_length = Gauge('wikipedia_hero_page_length_chars', 'Hero page length', ['hero_name'], registry=registry)
hero_page_rank = Gauge('wikipedia_hero_page_rank', 'Hero page popularity rank', ['hero_name'], registry=registry)
hero_last_modified = Gauge('wikipedia_hero_page_modified_unix', 'Hero page last modified time', ['hero_name'], registry=registry)
hero_num_sections = Gauge('wikipedia_hero_sections_count', 'Number of sections in article', ['hero_name'], registry=registry)
hero_num_references = Gauge('wikipedia_hero_references_count', 'Number of references', ['hero_name'], registry=registry)
hero_num_links = Gauge('wikipedia_hero_links_count', 'Number of links to other pages', ['hero_name'], registry=registry)

# –ì–†–£–ü–ü–ê 4: –†–ï–î–ê–ö–¶–ò–ò –ò –ü–†–ê–í–ö–ò (4 –º–µ—Ç—Ä–∏–∫–∏)
hero_revisions_total = Gauge('wikipedia_hero_revisions_total', 'Total revisions of page', ['hero_name'], registry=registry)
hero_editors_count = Gauge('wikipedia_hero_editors_count', 'Number of unique editors', ['hero_name'], registry=registry)
hero_page_views_total = Gauge('wikipedia_hero_page_views_total', 'Total page views', ['hero_name'], registry=registry)
most_edited_hero = Gauge('wikipedia_most_edited_hero_revisions', 'Revisions for most edited hero', registry=registry)

# –ì–†–£–ü–ü–ê 5: –ö–ê–¢–ï–ì–û–†–ò–ò –ò –Ø–ó–´–ö–ò (4 –º–µ—Ç—Ä–∏–∫–∏)
hero_categories_count = Gauge('wikipedia_hero_categories_count', 'Number of categories', ['hero_name'], registry=registry)
hero_languages_available = Gauge('wikipedia_hero_languages_count', 'Available language versions', ['hero_name'], registry=registry)
total_categories = Gauge('wikipedia_total_categories', 'Total unique categories', registry=registry)
total_languages_across_heroes = Gauge('wikipedia_total_languages_available', 'Total language versions available', registry=registry)

# –ì–†–£–ü–ü–ê 6: –†–ï–î–ò–†–ï–ö–¢–´ –ò –í–ê–†–ò–ê–¶–ò–ò (3 –º–µ—Ç—Ä–∏–∫–∏)
pages_as_redirects = Gauge('wikipedia_redirect_pages_count', 'Pages that are redirects', registry=registry)
most_common_word_frequency = Gauge('wikipedia_most_common_word_count', 'Frequency of most common word', registry=registry)
hero_disambiguation_pages = Gauge('wikipedia_disambiguation_pages_count', 'Disambiguation pages for heroes', registry=registry)

# –ì–†–£–ü–ü–ê 7: –ö–ê–ß–ï–°–¢–í–û –ò –°–¢–ê–¢–ò–°–¢–ò–ö–ê (3 –º–µ—Ç—Ä–∏–∫)
data_completeness = Gauge('wikipedia_data_completeness_percent', 'Data completeness %', registry=registry)
api_response_time = Histogram('wikipedia_api_response_time_seconds', 'API response time', registry=registry)
api_errors = Counter('wikipedia_api_errors_total', 'Total API errors', registry=registry)
api_calls = Counter('wikipedia_api_calls_total', 'Total API calls', registry=registry)

# ============================================================================
# –§–£–ù–ö–¶–ò–ò –î–õ–Ø –†–ê–ë–û–¢–´ –° API
# ============================================================================

def safe_int(value, default=0):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ int"""
    try:
        return int(value)
    except:
        return default


def fetch_page_info(hero_name):
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –≥–µ—Ä–æ—è"""
    try:
        api_calls.inc()
        start_time = time.time()
        
        params = {
            "action": "query",
            "format": "json",
            "titles": hero_name,
            "prop": "info|revisions|categories|langlinks|pageprops",
            "rvlimit": "1",
            "cllimit": "500",
            "lllimit": "500"
        }
        
        # –ì–õ–ê–í–ù–û–ï: –î–æ–±–∞–≤–ª—è–µ–º User-Agent!
        response = requests.get(API_BASE, params=params, headers=HEADERS, timeout=10)
        response_time = time.time() - start_time
        api_response_time.observe(response_time)
        
        if response.status_code == 200:
            data = response.json()
            logger.info(f"‚úÖ Fetched {hero_name}: 200 OK ({response_time:.2f}s)")
            return data
        else:
            logger.error(f"‚ùå API error for {hero_name}: status {response.status_code}")
            api_errors.inc()
            return None
            
    except requests.RequestException as e:
        logger.error(f"‚ùå Request failed for {hero_name}: {e}")
        api_errors.inc()
        return None
    except Exception as e:
        logger.error(f"‚ùå Unexpected error for {hero_name}: {e}")
        api_errors.inc()
        return None


def get_page_text_length(hero_name):
    """–ü–æ–ª—É—á–∏—Ç—å –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
    try:
        params = {
            "action": "query",
            "format": "json",
            "titles": hero_name,
            "prop": "extracts",
            "explaintext": True
        }
        
        response = requests.get(API_BASE, params=params, headers=HEADERS, timeout=10)
        if response.status_code == 200:
            data = response.json()
            pages = data.get('query', {}).get('pages', {})
            for page_id, page_data in pages.items():
                extract = page_data.get('extract', '')
                return len(extract)
        return 0
    except:
        return 0


def update_metrics():
    """–û–±–Ω–æ–≤–∏—Ç—å –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ API"""
    logger.info("üì° Updating metrics from Wikipedia API...")
    
    total_heroes_monitored.set(len(HEROES))
    
    total_length = 0
    total_refs = 0
    total_sections = 0
    total_links = 0
    max_length = 0
    max_revisions = 0
    all_categories = set()
    all_languages = set()
    success_count = 0
    
    for hero_name in HEROES:
        data = fetch_page_info(hero_name)
        if not data:
            logger.warning(f"‚ö†Ô∏è  No data for {hero_name}")
            continue
        
        try:
            pages = data.get('query', {}).get('pages', {})
            
            for page_id, page_info in pages.items():
                # –ü—Ä–æ–ø—É—Å–∫ –µ—Å–ª–∏ —ç—Ç–æ —Ä–µ–¥–∏—Ä–µ–∫—Ç –∏–ª–∏ –æ—à–∏–±–∫–∞
                if 'missing' in page_info:
                    logger.warning(f"‚ö†Ô∏è  {hero_name} not found on Wikipedia")
                    continue
                
                success_count += 1
                
                # –û–°–ù–û–í–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø
                title = page_info.get('title', hero_name)
                page_length = safe_int(page_info.get('length', 0))
                revisions = safe_int(page_info.get('lastrevid', 0))
                
                hero_page_length.labels(hero_name=hero_name).set(page_length)
                
                total_length += page_length
                if page_length > max_length:
                    max_length = page_length
                
                # –†–ï–î–ê–ö–¶–ò–ò
                revisions_data = page_info.get('revisions', [])
                if revisions_data:
                    rev_count = len(revisions_data)
                    hero_revisions_total.labels(hero_name=hero_name).set(rev_count)
                    if rev_count > max_revisions:
                        max_revisions = rev_count
                
                # –ö–ê–¢–ï–ì–û–†–ò–ò
                categories = page_info.get('categories', [])
                hero_categories_count.labels(hero_name=hero_name).set(len(categories))
                for cat in categories:
                    all_categories.add(cat.get('title', ''))
                
                # –Ø–ó–´–ö–ò
                langlinks = page_info.get('langlinks', [])
                hero_languages_available.labels(hero_name=hero_name).set(len(langlinks))
                for ll in langlinks:
                    all_languages.add(ll.get('lang', ''))
                
                logger.info(f"üìä {hero_name}: {page_length}chars, {len(categories)}cats, {len(langlinks)}langs")
            
        except Exception as e:
            logger.error(f"‚ùå Error parsing data for {hero_name}: {e}")
            continue
    
    # –ò–¢–û–ì–û–í–´–ï –ú–ï–¢–†–ò–ö–ò
    total_hero_pages.set(success_count)
    avg_page_length.set(total_length / success_count if success_count > 0 else 0)
    max_page_length.set(max_length)
    most_edited_hero.set(max_revisions)
    total_categories.set(len(all_categories))
    total_languages_across_heroes.set(len(all_languages))
    
    data_completeness.set(100)
    
    logger.info(f"‚úÖ All metrics updated: {success_count}/{len(HEROES)} heroes, {len(all_categories)} categories, {len(all_languages)} languages")


def metrics_update_loop():
    """–ë–µ—Å–∫–æ–Ω–µ—á–Ω—ã–π —Ü–∏–∫–ª –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫"""
    while True:
        try:
            update_metrics()
        except Exception as e:
            logger.error(f"‚ùå Error in update loop: {e}")
        
        time.sleep(SCRAPE_INTERVAL)


# ============================================================================
# HTTP HANDLER
# ============================================================================

class MetricsHandler(BaseHTTPRequestHandler):
    """HTTP –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è Prometheus /metrics endpoint"""
    
    def do_GET(self):
        if self.path == '/metrics':
            self.send_response(200)
            self.send_header('Content-type', 'text/plain; version=0.0.4; charset=utf-8')
            self.end_headers()
            self.wfile.write(generate_latest(registry))
        elif self.path == '/health':
            self.send_response(200)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            self.wfile.write(b'{"status":"healthy","exporter":"wikipedia"}')
        else:
            self.send_response(404)
            self.end_headers()
    
    def log_message(self, format, *args):
        return


# ============================================================================
# MAIN
# ============================================================================

def main():
    logger.info("=" * 70)
    logger.info("üìö Wikipedia API Exporter Starting (FIXED)")
    logger.info("=" * 70)
    logger.info(f"üîÑ Update interval: {SCRAPE_INTERVAL} seconds")
    logger.info(f"üåê Metrics endpoint: http://localhost:{EXPORTER_PORT}/metrics")
    logger.info(f"ü¶∏ Monitoring {len(HEROES)} superheroes")
    logger.info(f"‚≠ê User-Agent: Added (Wikipedia requirement)")
    
    # –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ—Ç–æ–∫ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫
    update_thread = Thread(target=metrics_update_loop, daemon=True)
    update_thread.start()
    logger.info("‚úÖ Metrics update thread started")
    
    # –ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
    logger.info("üì° Fetching initial metrics...")
    update_metrics()
    
    # –ó–∞–ø—É—Å—Ç–∏—Ç—å HTTP —Å–µ—Ä–≤–µ—Ä
    server = HTTPServer(('0.0.0.0', EXPORTER_PORT), MetricsHandler)
    logger.info(f"‚úÖ HTTP server started on port {EXPORTER_PORT}")
    logger.info("=" * 70)
    
    try:
        server.serve_forever()
    except KeyboardInterrupt:
        logger.info("\nüõë Shutting down...")
        server.shutdown()
        logger.info("‚úÖ Exporter stopped")


if __name__ == '__main__':
    main()